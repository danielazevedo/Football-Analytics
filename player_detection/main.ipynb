{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FQUBev3UN3n"
   },
   "source": [
    "# Player Detection\n",
    "\n",
    "Use Yolov3 for **detecting players** and **detecting and classifying their shirt number**\n",
    "\n",
    "More details here: https://medium.com/analytics-vidhya/player-detection-using-deep-learning-492122c3bf9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuGxKLTOW63E"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuZ6NGi1Xvtf",
    "outputId": "1d77abd9-a6e6-4a24-8c10-1cd9ca83088f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPf0_yK0UgNQ"
   },
   "source": [
    "## Load number detection and number classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uii7Rp5sXvws"
   },
   "outputs": [],
   "source": [
    "drive_path = 'drive/MyDrive/Colab Notebooks/'\n",
    "data_path = 'drive/MyDrive/Colab Notebooks/numbers_detection/'\n",
    "darknet_path = 'drive/MyDrive/Colab Notebooks/darknet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6wJU59DXUM0"
   },
   "outputs": [],
   "source": [
    "classifier_numbers = tf.keras.models.load_model(data_path+'numbers_classifier_aug.h5')\n",
    "classifier_bbox_numbers = tf.keras.models.load_model(data_path+'number_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXskfT-oXUP0"
   },
   "outputs": [],
   "source": [
    "# run number detection model on a given image\n",
    "def detect_numbers(image):\n",
    "    image = cv2.resize(image, dsize=(224, 224))\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    preds_bbox = classifier_bbox_numbers.predict(image)[0]\n",
    "    (startX, startY, endX, endY) = preds_bbox\n",
    "    \n",
    "    return (startX, startY, endX, endY)\n",
    "\n",
    "# run number classification model on a given image\n",
    "def identify_numbers(image):\n",
    "    \n",
    "    #image = rgb2gray(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image = np.zeros_like(image)\n",
    "    image[:,:,0] = gray\n",
    "    \n",
    "    image[:,:,1] = gray\n",
    "    image[:,:,2] = gray\n",
    "\n",
    "    image = cv2.GaussianBlur(cv2.resize(image, dsize=(224, 224)), (5,5), 0)\n",
    "    \n",
    "    copy_image = image.copy()\n",
    "    \n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    preds = classifier_numbers.predict(image)[0]\n",
    "    \n",
    "    i = np.argmax(preds)\n",
    "    \n",
    "    if preds[i] > 0.4:\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeBWNL7EZgKz"
   },
   "outputs": [],
   "source": [
    "filename = 'example.mp4'\n",
    "input_video_path = f'{data_path}/video_samples/input/{filename}'\n",
    "output_video_path = f'{data_path}/video_samples/output/{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D5GmYiswXUSP"
   },
   "outputs": [],
   "source": [
    "# initialize minimum probability to eliminate weak predictions\n",
    "p_min = 0.5\n",
    "\n",
    "# threshold when applying non-maxia suppression\n",
    "thres = 0.\n",
    "\n",
    "# 'VideoCapture' object and reading vicv2.mean(image, mask=mask)deo from a file\n",
    "video = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Preparing variable for writer\n",
    "# that we will use to write processed frames\n",
    "writer = None\n",
    "\n",
    "# Preparing variables for spatial dimensions of the frames\n",
    "h, w = None, None\n",
    "\n",
    "# Create labels into list\n",
    "with open(drive_path+'coco.names') as f:\n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "np.random.seed(30)\n",
    "# Initialize colours for representing every detected object\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3))\n",
    "colours[0] = np.array([255, 0, 0])\n",
    "\n",
    "# Loading trained YOLO v3 Objects Detector\n",
    "# with the help of 'dnn' library from OpenCV\n",
    "# Reads a network model stored in Darknet model files.\n",
    "network = cv2.dnn.readNet(drive_path+'darknet/cfg/yolov3.weights', drive_path+'darknet/cfg/yolov3.cfg')\n",
    "\n",
    "\n",
    "# Getting only output layer names that we need from YOLO\n",
    "ln = network.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "# Defining loop for catching frames\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Getting dimensions of the frame for once as everytime dimensions will be same\n",
    "    if w is None or h is None:\n",
    "        # Slicing and get height, width of the image\n",
    "        Height, Width = frame.shape[:2]\n",
    "\n",
    "    # frame preprocessing for deep learning\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                                 swapRB=True, crop=False)\n",
    "\n",
    "    # perform a forward pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities.\n",
    "    network.setInput(blob)\n",
    "    output_from_network = network.forward(ln)\n",
    "\n",
    "    # Preparing lists for detected bounding boxes, confidences and class numbers.\n",
    "    numbers_bboxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "    preds_number = []\n",
    "    boxes = []\n",
    "    \n",
    "    # Going through all output layers after feed forward pass\n",
    "    for result in output_from_network:\n",
    "        \n",
    "        for detected_objects in result:\n",
    "            \n",
    "            scores = detected_objects[5:]\n",
    "            class_current = np.argmax(scores)\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            if confidence_current > 0.1:\n",
    "                \n",
    "                center_x = int(detected_objects[0] * Width)\n",
    "                center_y = int(detected_objects[1] * Height)\n",
    "                w = int(detected_objects[2] * Width)\n",
    "                h = int(detected_objects[3] * Height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                player_image = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                if player_image.shape[0] == 0 or player_image.shape[1] == 0 or player_image.shape[2] == 0:\n",
    "                    continue\n",
    "                \n",
    "                 # detect numbers bbox\n",
    "                (startX, startY, endX, endY) = detect_numbers(player_image)\n",
    "\n",
    "                pad_h, pad_w = h * 0.05, w * 0.1\n",
    "\n",
    "                startX = int(startX * w - pad_w)\n",
    "                startY = int(startY * h + pad_h)\n",
    "                endX = int(endX * w + pad_w)\n",
    "                endY = int(endY * h - pad_h)\n",
    "\n",
    "                if startX == endX or endY == startY:\n",
    "                    continue\n",
    "\n",
    "                n_bbox = player_image[endY:startY, startX:endX, :]\n",
    "                if n_bbox.shape[0] == 0 or n_bbox.shape[1] == 0 or n_bbox.shape[2] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                number_pred = identify_numbers(n_bbox)\n",
    "\n",
    "                if number_pred != -1:\n",
    "                    numbers_bboxes.append([startX + x, startY + y, endX + x, endY + y])\n",
    "                    class_numbers.append(class_current)\n",
    "                    confidences.append(float(confidence_current))\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    preds_number.append(number_pred)\n",
    "                \n",
    "                \n",
    "\n",
    "    \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "\n",
    "    #check if is people detection\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        box_numbers = numbers_bboxes[i]\n",
    "\n",
    "        if class_numbers[i] == 0:\n",
    "            cv2.rectangle(frame, (round(box_numbers[0]),round(box_numbers[1])), (round(box_numbers[2]),round(box_numbers[3])), (255, 0, 0), 2)\n",
    "            cv2.rectangle(frame, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (0, 0, 0), 2)\n",
    "            cv2.putText(frame, f'Player {preds_number[i]}', (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Store proccessed frames into result video.\"\"\"\n",
    "    # Initialize writer\n",
    "    if writer is None:\n",
    "        resultVideo = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "        # Writing current processed frame into the video file\n",
    "        writer = cv2.VideoWriter(output_video_path, resultVideo, 15,\n",
    "                                 (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    # Write processed current frame to the file\n",
    "    writer.write(frame)\n",
    "\n",
    "# Releasing video reader and writer\n",
    "video.release()\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
